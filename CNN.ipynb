{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalMaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 数据集加载及数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 设立超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x_train,y_train：训练的样本的数据和labels \n",
    "x_test,y_test：测试的样本的数据和labels \n",
    "dtype=int,0~255 \n",
    "\"\"\"\n",
    "\n",
    "batch_size = 32 \n",
    "num_classes = 10\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#转成one-hot编码\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 模型搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1模型介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential:顺序模型\n",
    "\n",
    "Activation：激活层，通过激活函数对张量进行激活 \n",
    "Dense：全连接\n",
    "Dropout:drouput层，以一定概率不激活神经元，防止过拟合 \n",
    "Flatten：把多维输入一维化\n",
    "\n",
    "Conv2D：2d卷积\n",
    "MaxPooling2D：2d下采样,把一维的向量转换为num_class维的One-hot编码 \n",
    "\n",
    "plot_model：打印建好的模型，相当于可视化模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2搭建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               32500     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 139,930\n",
      "Trainable params: 139,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#第一,二层：32个（33）的卷积核，步长为1（默认也是1）\n",
    "#input_shape：神经网络输入的张量的大小是多少\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
    "#激活函数选择‘relu’\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "#Maxpooling:池化核的大小，22，步长strides默认和池化大小一致\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(GlobalMaxPooling2D())\n",
    "\n",
    "# Dense（100）表示把他压成和我们labels一样的维度100，通过softmax进行激活\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 训练模型\n",
    "model.compile:进行编译\n",
    "optimizer：随机梯度下降优化器，这里使用的是Adam，学习率是0，0001\n",
    "loss='categorical_crossentropy'：多分类用的one-hot交叉熵 \n",
    "model.fit(X_train,y_train,epochs=600,batch_size=128,)：进行300轮，批次为128的训练，默认训练过程中是会加入正则化防止过拟合。 loss,acc=model.evaluate(x_test,y_test)：对样本进行测试，默认不使用正则化，返回损失值和正确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train____________\n",
      "Epoch 1/300\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 2.1784 - acc: 0.1782\n",
      "Epoch 2/300\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 1.9075 - acc: 0.2954\n",
      "Epoch 3/300\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 1.7457 - acc: 0.3586\n",
      "Epoch 4/300\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.6577 - acc: 0.3918\n",
      "Epoch 5/300\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 1.6001 - acc: 0.4143\n",
      "Epoch 6/300\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 1.5569 - acc: 0.4291\n",
      "Epoch 7/300\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 1.5226 - acc: 0.4411\n",
      "Epoch 8/300\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 1.4949 - acc: 0.4540\n",
      "Epoch 9/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.4653 - acc: 0.4646\n",
      "Epoch 10/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.4421 - acc: 0.4749: 0s - loss: 1.4427 - acc: 0.\n",
      "Epoch 11/300\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.4216 - acc: 0.4861\n",
      "Epoch 12/300\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 1.4010 - acc: 0.4919\n",
      "Epoch 13/300\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 1.3841 - acc: 0.4995\n",
      "Epoch 14/300\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 1.3661 - acc: 0.5035\n",
      "Epoch 15/300\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.3529 - acc: 0.5117: 2s - loss: 1.3528 \n",
      "Epoch 16/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.3358 - acc: 0.5192\n",
      "Epoch 17/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.3209 - acc: 0.5237\n",
      "Epoch 18/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.3126 - acc: 0.5272: 3s - los\n",
      "Epoch 19/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.2954 - acc: 0.5337\n",
      "Epoch 20/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.2850 - acc: 0.5361\n",
      "Epoch 21/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.2718 - acc: 0.5408\n",
      "Epoch 22/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.2608 - acc: 0.5465\n",
      "Epoch 23/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.2522 - acc: 0.5491\n",
      "Epoch 24/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.2396 - acc: 0.5564: 9s - loss: 1.241\n",
      "Epoch 25/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.2304 - acc: 0.5595\n",
      "Epoch 26/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.2188 - acc: 0.5632\n",
      "Epoch 27/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.2081 - acc: 0.5697\n",
      "Epoch 28/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.2005 - acc: 0.5664\n",
      "Epoch 29/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.1905 - acc: 0.5732\n",
      "Epoch 30/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.1799 - acc: 0.5762\n",
      "Epoch 31/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.1722 - acc: 0.5815\n",
      "Epoch 32/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.1622 - acc: 0.5854: 2s - loss: 1.16\n",
      "Epoch 33/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.1556 - acc: 0.5891\n",
      "Epoch 34/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.1505 - acc: 0.5898\n",
      "Epoch 35/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.1370 - acc: 0.5960\n",
      "Epoch 36/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.1323 - acc: 0.5969\n",
      "Epoch 37/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.1247 - acc: 0.5991\n",
      "Epoch 38/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.1179 - acc: 0.6034\n",
      "Epoch 39/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.1109 - acc: 0.6054\n",
      "Epoch 40/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.1033 - acc: 0.6105\n",
      "Epoch 41/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0986 - acc: 0.6125\n",
      "Epoch 42/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0869 - acc: 0.6142: 3s - loss: 1.0848 - acc: 0.61 - ETA: 3s - loss: \n",
      "Epoch 43/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.0851 - acc: 0.6158\n",
      "Epoch 44/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0761 - acc: 0.6168\n",
      "Epoch 45/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0704 - acc: 0.6218\n",
      "Epoch 46/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0675 - acc: 0.6212\n",
      "Epoch 47/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0582 - acc: 0.6252\n",
      "Epoch 48/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0562 - acc: 0.6258\n",
      "Epoch 49/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0454 - acc: 0.6293\n",
      "Epoch 50/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0401 - acc: 0.6319\n",
      "Epoch 51/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0379 - acc: 0.6325\n",
      "Epoch 52/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0351 - acc: 0.6331\n",
      "Epoch 53/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0246 - acc: 0.6359\n",
      "Epoch 54/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 1.0168 - acc: 0.6404\n",
      "Epoch 55/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0159 - acc: 0.6392: 10s - l -\n",
      "Epoch 56/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0096 - acc: 0.6435\n",
      "Epoch 57/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.0059 - acc: 0.6450\n",
      "Epoch 58/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9982 - acc: 0.6453: 4s - loss: 0.9992 - - ETA: 2s - loss: 0.9\n",
      "Epoch 59/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9962 - acc: 0.6465\n",
      "Epoch 60/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9891 - acc: 0.6491\n",
      "Epoch 61/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9865 - acc: 0.6513\n",
      "Epoch 62/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9832 - acc: 0.6516\n",
      "Epoch 63/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9760 - acc: 0.6566: 4s - l\n",
      "Epoch 64/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9720 - acc: 0.6568\n",
      "Epoch 65/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9683 - acc: 0.6579\n",
      "Epoch 66/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9613 - acc: 0.6582\n",
      "Epoch 67/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9566 - acc: 0.6595\n",
      "Epoch 68/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.9561 - acc: 0.6655\n",
      "Epoch 69/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.9484 - acc: 0.6652\n",
      "Epoch 70/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.9443 - acc: 0.6653\n",
      "Epoch 71/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.9385 - acc: 0.6691\n",
      "Epoch 72/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9370 - acc: 0.6697\n",
      "Epoch 73/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9323 - acc: 0.6703\n",
      "Epoch 74/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9227 - acc: 0.6747\n",
      "Epoch 75/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.9236 - acc: 0.6736: 3s - los\n",
      "Epoch 76/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.9227 - acc: 0.6745\n",
      "Epoch 77/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.9167 - acc: 0.6753\n",
      "Epoch 78/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9122 - acc: 0.6771\n",
      "Epoch 79/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9113 - acc: 0.6762\n",
      "Epoch 80/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.9042 - acc: 0.6817\n",
      "Epoch 81/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9005 - acc: 0.6798\n",
      "Epoch 82/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8978 - acc: 0.6833\n",
      "Epoch 83/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8927 - acc: 0.6854\n",
      "Epoch 84/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8893 - acc: 0.6849\n",
      "Epoch 85/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8839 - acc: 0.6883\n",
      "Epoch 86/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8846 - acc: 0.6868\n",
      "Epoch 87/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8828 - acc: 0.6886\n",
      "Epoch 88/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8810 - acc: 0.6897: 1s - loss: 0.8809 - ac\n",
      "Epoch 89/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8703 - acc: 0.6934\n",
      "Epoch 90/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8730 - acc: 0.6911\n",
      "Epoch 91/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8654 - acc: 0.6941: 0s - loss: 0.8656 - acc: 0\n",
      "Epoch 92/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8651 - acc: 0.6954: \n",
      "Epoch 93/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8618 - acc: 0.6969\n",
      "Epoch 94/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8563 - acc: 0.6976\n",
      "Epoch 95/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8538 - acc: 0.7014\n",
      "Epoch 96/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8547 - acc: 0.6970\n",
      "Epoch 97/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8465 - acc: 0.7032\n",
      "Epoch 98/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8435 - acc: 0.7030\n",
      "Epoch 99/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8439 - acc: 0.7014\n",
      "Epoch 100/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8373 - acc: 0.7043\n",
      "Epoch 101/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8384 - acc: 0.7040\n",
      "Epoch 102/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8301 - acc: 0.7077\n",
      "Epoch 103/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8342 - acc: 0.7047\n",
      "Epoch 104/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8263 - acc: 0.7095: 2s - loss: 0.8265 -\n",
      "Epoch 105/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8253 - acc: 0.7092\n",
      "Epoch 106/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8220 - acc: 0.7098\n",
      "Epoch 107/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8152 - acc: 0.7121\n",
      "Epoch 108/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8132 - acc: 0.7142: 4s - lo\n",
      "Epoch 109/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8164 - acc: 0.7103\n",
      "Epoch 110/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8083 - acc: 0.7159\n",
      "Epoch 111/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8062 - acc: 0.7148: \n",
      "Epoch 112/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.8043 - acc: 0.7146\n",
      "Epoch 113/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.8010 - acc: 0.7178: 4s - l\n",
      "Epoch 114/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7987 - acc: 0.7189\n",
      "Epoch 115/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7985 - acc: 0.7185\n",
      "Epoch 116/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.7926 - acc: 0.7201\n",
      "Epoch 117/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7914 - acc: 0.7203\n",
      "Epoch 118/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.7867 - acc: 0.7224: 8s - ETA: 3s - loss:\n",
      "Epoch 119/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.7859 - acc: 0.7242: 1s - loss: 0.7856 - acc\n",
      "Epoch 120/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7855 - acc: 0.7235\n",
      "Epoch 121/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.7812 - acc: 0.7265\n",
      "Epoch 122/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.7802 - acc: 0.7262\n",
      "Epoch 123/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.7784 - acc: 0.7252\n",
      "Epoch 124/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7739 - acc: 0.7266\n",
      "Epoch 125/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7697 - acc: 0.7293\n",
      "Epoch 126/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7668 - acc: 0.7298\n",
      "Epoch 127/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7666 - acc: 0.7294\n",
      "Epoch 128/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7637 - acc: 0.7305\n",
      "Epoch 129/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.7616 - acc: 0.7339\n",
      "Epoch 130/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7565 - acc: 0.7355\n",
      "Epoch 131/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7549 - acc: 0.7333\n",
      "Epoch 132/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7517 - acc: 0.7371\n",
      "Epoch 133/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.7544 - acc: 0.7331:\n",
      "Epoch 134/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7501 - acc: 0.7362\n",
      "Epoch 135/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7494 - acc: 0.7351\n",
      "Epoch 136/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7495 - acc: 0.7345\n",
      "Epoch 137/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7448 - acc: 0.7380\n",
      "Epoch 138/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7390 - acc: 0.7383\n",
      "Epoch 139/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7426 - acc: 0.7402\n",
      "Epoch 140/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7363 - acc: 0.7405\n",
      "Epoch 141/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7344 - acc: 0.7425\n",
      "Epoch 142/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.7351 - acc: 0.7405\n",
      "Epoch 143/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7301 - acc: 0.7423\n",
      "Epoch 144/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7284 - acc: 0.7411\n",
      "Epoch 145/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7286 - acc: 0.7429\n",
      "Epoch 146/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7229 - acc: 0.7446\n",
      "Epoch 147/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7186 - acc: 0.7469\n",
      "Epoch 148/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7214 - acc: 0.7455\n",
      "Epoch 149/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7177 - acc: 0.7462\n",
      "Epoch 150/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7165 - acc: 0.7459: 1s - loss: 0.7168 - a\n",
      "Epoch 151/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7178 - acc: 0.7474\n",
      "Epoch 152/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7072 - acc: 0.7515\n",
      "Epoch 153/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7116 - acc: 0.7490: 5\n",
      "Epoch 154/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7093 - acc: 0.7512A: 0s - loss: 0.7092 - acc: 0.751\n",
      "Epoch 155/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7018 - acc: 0.7539\n",
      "Epoch 156/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7070 - acc: 0.7499\n",
      "Epoch 157/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.7024 - acc: 0.7505\n",
      "Epoch 158/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.7001 - acc: 0.7526\n",
      "Epoch 159/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6950 - acc: 0.7567\n",
      "Epoch 160/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6980 - acc: 0.7555\n",
      "Epoch 161/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6958 - acc: 0.7532\n",
      "Epoch 162/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6962 - acc: 0.7550\n",
      "Epoch 163/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6906 - acc: 0.7563\n",
      "Epoch 164/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6904 - acc: 0.7559\n",
      "Epoch 165/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6859 - acc: 0.7576\n",
      "Epoch 166/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6841 - acc: 0.7583: 4s\n",
      "Epoch 167/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6825 - acc: 0.7586\n",
      "Epoch 168/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6830 - acc: 0.7603: 3s - loss\n",
      "Epoch 169/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6781 - acc: 0.7599\n",
      "Epoch 170/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6736 - acc: 0.7628: 0s - loss: 0.6734 - acc: 0.763\n",
      "Epoch 171/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6756 - acc: 0.7599\n",
      "Epoch 172/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6736 - acc: 0.7638\n",
      "Epoch 173/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6698 - acc: 0.7634: 4s -\n",
      "Epoch 174/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6745 - acc: 0.7614\n",
      "Epoch 175/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6681 - acc: 0.7635\n",
      "Epoch 176/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6660 - acc: 0.7638\n",
      "Epoch 177/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6662 - acc: 0.7641\n",
      "Epoch 178/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6627 - acc: 0.7658\n",
      "Epoch 179/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6616 - acc: 0.7664\n",
      "Epoch 180/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6604 - acc: 0.7672\n",
      "Epoch 181/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6562 - acc: 0.7708\n",
      "Epoch 182/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6583 - acc: 0.7671\n",
      "Epoch 183/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6554 - acc: 0.7680\n",
      "Epoch 184/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6545 - acc: 0.7684: 4s\n",
      "Epoch 185/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6517 - acc: 0.7696\n",
      "Epoch 186/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6443 - acc: 0.7756\n",
      "Epoch 187/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6490 - acc: 0.7704\n",
      "Epoch 188/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6483 - acc: 0.7738\n",
      "Epoch 189/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6468 - acc: 0.7729\n",
      "Epoch 190/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6421 - acc: 0.7729\n",
      "Epoch 191/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6386 - acc: 0.7755\n",
      "Epoch 192/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6377 - acc: 0.7752\n",
      "Epoch 193/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6408 - acc: 0.7744\n",
      "Epoch 194/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.6366 - acc: 0.7743: 3s - los\n",
      "Epoch 195/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.6379 - acc: 0.7766\n",
      "Epoch 196/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6354 - acc: 0.7765\n",
      "Epoch 197/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6342 - acc: 0.7757\n",
      "Epoch 198/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6302 - acc: 0.7789\n",
      "Epoch 199/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6335 - acc: 0.7751\n",
      "Epoch 200/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6271 - acc: 0.7770\n",
      "Epoch 201/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6302 - acc: 0.7775\n",
      "Epoch 202/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6245 - acc: 0.7795\n",
      "Epoch 203/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6226 - acc: 0.7813\n",
      "Epoch 204/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6214 - acc: 0.7788\n",
      "Epoch 205/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6175 - acc: 0.7821\n",
      "Epoch 206/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6247 - acc: 0.7808\n",
      "Epoch 207/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6180 - acc: 0.7829: 5\n",
      "Epoch 208/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6189 - acc: 0.7825\n",
      "Epoch 209/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6154 - acc: 0.7816\n",
      "Epoch 210/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6171 - acc: 0.7815\n",
      "Epoch 211/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6140 - acc: 0.7831: 4s \n",
      "Epoch 212/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6099 - acc: 0.7837\n",
      "Epoch 213/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6081 - acc: 0.7854\n",
      "Epoch 214/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6068 - acc: 0.7855\n",
      "Epoch 215/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6083 - acc: 0.7854\n",
      "Epoch 216/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.6021 - acc: 0.7879\n",
      "Epoch 217/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6072 - acc: 0.7844\n",
      "Epoch 218/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.6012 - acc: 0.7873\n",
      "Epoch 219/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5992 - acc: 0.7880\n",
      "Epoch 220/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5999 - acc: 0.7876\n",
      "Epoch 221/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5979 - acc: 0.7880\n",
      "Epoch 222/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5922 - acc: 0.7900\n",
      "Epoch 223/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5972 - acc: 0.7881: 2s - loss: 0.597\n",
      "Epoch 224/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5903 - acc: 0.7898\n",
      "Epoch 225/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5916 - acc: 0.7910\n",
      "Epoch 226/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5953 - acc: 0.7893\n",
      "Epoch 227/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5952 - acc: 0.7894\n",
      "Epoch 228/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5878 - acc: 0.7924\n",
      "Epoch 229/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5875 - acc: 0.7947: \n",
      "Epoch 230/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5873 - acc: 0.7917\n",
      "Epoch 231/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5845 - acc: 0.7927\n",
      "Epoch 232/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5855 - acc: 0.7922: 2s - loss: 0.5855\n",
      "Epoch 233/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5801 - acc: 0.7944\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5830 - acc: 0.7938: 0s - loss: 0.5830 - acc: 0\n",
      "Epoch 235/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5778 - acc: 0.7950\n",
      "Epoch 236/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5796 - acc: 0.7974\n",
      "Epoch 237/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5761 - acc: 0.7960\n",
      "Epoch 238/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5741 - acc: 0.7958\n",
      "Epoch 239/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5747 - acc: 0.7972\n",
      "Epoch 240/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5724 - acc: 0.7978\n",
      "Epoch 241/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5736 - acc: 0.7969\n",
      "Epoch 242/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5708 - acc: 0.7980\n",
      "Epoch 243/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5675 - acc: 0.7982\n",
      "Epoch 244/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5697 - acc: 0.7998\n",
      "Epoch 245/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5677 - acc: 0.7977\n",
      "Epoch 246/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.5637 - acc: 0.8002\n",
      "Epoch 247/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5679 - acc: 0.7978\n",
      "Epoch 248/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5625 - acc: 0.8013: 2s - loss: 0.5632 -\n",
      "Epoch 249/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5653 - acc: 0.8002\n",
      "Epoch 250/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5613 - acc: 0.7996\n",
      "Epoch 251/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5600 - acc: 0.7999\n",
      "Epoch 252/300\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.5585 - acc: 0.8025\n",
      "Epoch 253/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5581 - acc: 0.8024\n",
      "Epoch 254/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5560 - acc: 0.8039\n",
      "Epoch 255/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.5565 - acc: 0.8038\n",
      "Epoch 256/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.5540 - acc: 0.8038\n",
      "Epoch 257/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5516 - acc: 0.8049\n",
      "Epoch 258/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5527 - acc: 0.8028: 0s - loss: 0.5528 - acc: 0.802\n",
      "Epoch 259/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5497 - acc: 0.8060\n",
      "Epoch 260/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5477 - acc: 0.8071\n",
      "Epoch 261/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.5496 - acc: 0.8049\n",
      "Epoch 262/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5434 - acc: 0.8068\n",
      "Epoch 263/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5465 - acc: 0.8073: 0s - loss: 0.5464 - acc: 0.807\n",
      "Epoch 264/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5422 - acc: 0.8071: 5\n",
      "Epoch 265/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5425 - acc: 0.8070: \n",
      "Epoch 266/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5421 - acc: 0.8091: 0s - loss: 0.5421 - acc: 0.\n",
      "Epoch 267/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.5386 - acc: 0.8071\n",
      "Epoch 268/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5422 - acc: 0.8068\n",
      "Epoch 269/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5362 - acc: 0.8096\n",
      "Epoch 270/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5400 - acc: 0.8091\n",
      "Epoch 271/300\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.5372 - acc: 0.8102\n",
      "Epoch 272/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5350 - acc: 0.8097\n",
      "Epoch 273/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5377 - acc: 0.8093\n",
      "Epoch 274/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5388 - acc: 0.8087\n",
      "Epoch 275/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5302 - acc: 0.8115\n",
      "Epoch 276/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5325 - acc: 0.8117\n",
      "Epoch 277/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5283 - acc: 0.8127\n",
      "Epoch 278/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5276 - acc: 0.8126\n",
      "Epoch 279/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5259 - acc: 0.8125\n",
      "Epoch 280/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5277 - acc: 0.8123: 2s - loss: 0.5277 -\n",
      "Epoch 281/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5245 - acc: 0.8134: 4s - lo\n",
      "Epoch 282/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5261 - acc: 0.8150\n",
      "Epoch 283/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5239 - acc: 0.8143\n",
      "Epoch 284/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5223 - acc: 0.8143\n",
      "Epoch 285/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5218 - acc: 0.8151\n",
      "Epoch 286/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5216 - acc: 0.8164\n",
      "Epoch 287/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5226 - acc: 0.8139\n",
      "Epoch 288/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5173 - acc: 0.8147: 4s - lo\n",
      "Epoch 289/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5161 - acc: 0.8167\n",
      "Epoch 290/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5153 - acc: 0.8158\n",
      "Epoch 291/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5158 - acc: 0.8149\n",
      "Epoch 292/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5144 - acc: 0.8179\n",
      "Epoch 293/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5150 - acc: 0.8162\n",
      "Epoch 294/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5167 - acc: 0.8153: 6s - ETA: 1s - loss: 0.5174 - acc\n",
      "Epoch 295/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5115 - acc: 0.8181: 4s - l\n",
      "Epoch 296/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5092 - acc: 0.8187\n",
      "Epoch 297/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5119 - acc: 0.8172\n",
      "Epoch 298/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5105 - acc: 0.8177\n",
      "Epoch 299/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5087 - acc: 0.8180\n",
      "Epoch 300/300\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.5091 - acc: 0.8186\n",
      "test_____________\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "print(\"train____________\")\n",
    "model.fit(x_train,y_train,epochs=300,batch_size=128,)\n",
    "print(\"test_____________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 453us/step\n",
      "loss= 0.7131511684417725\n",
      "accuracy= 0.7541\n"
     ]
    }
   ],
   "source": [
    "loss,acc=model.evaluate(x_test,y_test)\n",
    "print(\"loss=\",loss)\n",
    "print(\"accuracy=\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
